{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOALS OF THE NOTEBOOK\n",
    "\n",
    "In this repo I want to try and create a relational map of a movie database based on the information parsed from the database. First dataset we will use is a more limited set. However, later we will go through a Netflix dataset that we have generated. The end goal should be two fully fleshed out dendrograms. This will largely be demonstrating the python data analysis, statistics, and machine learning tools and technology I have been self learning.\n",
    "\n",
    "The datasets we will be using are a mash of sets found from Kaggle, Github, and Datacamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies loaded: 100 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>wiki_plot</th>\n",
       "      <th>imdb_plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>[u' Crime', u' Drama']</td>\n",
       "      <td>On the day of his only daughter's wedding, Vit...</td>\n",
       "      <td>In late summer 1945, guests are gathered for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>[u' Crime', u' Drama']</td>\n",
       "      <td>In 1947, banker Andy Dufresne is convicted of ...</td>\n",
       "      <td>In 1947, Andy Dufresne (Tim Robbins), a banker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>[u' Biography', u' Drama', u' History']</td>\n",
       "      <td>In 1939, the Germans move Polish Jews into the...</td>\n",
       "      <td>The relocation of Polish Jews from surrounding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Raging Bull</td>\n",
       "      <td>[u' Biography', u' Drama', u' Sport']</td>\n",
       "      <td>In a brief scene in 1964, an aging, overweight...</td>\n",
       "      <td>The film opens in 1964, where an older and fat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Casablanca</td>\n",
       "      <td>[u' Drama', u' Romance', u' War']</td>\n",
       "      <td>It is early December 1941. American expatriate...</td>\n",
       "      <td>In the early years of World War II, December 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>Rebel Without a Cause</td>\n",
       "      <td>[u' Drama']</td>\n",
       "      <td>\\n\\n\\n\\nJim Stark is in police custody.\\n\\n  \\...</td>\n",
       "      <td>Shortly after moving to Los Angeles with his p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>Rear Window</td>\n",
       "      <td>[u' Mystery', u' Thriller']</td>\n",
       "      <td>\\n\\n\\n\\nJames Stewart as L.B. Jefferies\\n\\n  \\...</td>\n",
       "      <td>L.B. \"Jeff\" Jeffries (James Stewart) recuperat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>The Third Man</td>\n",
       "      <td>[u' Film-Noir', u' Mystery', u' Thriller']</td>\n",
       "      <td>\\n\\n\\n\\nSocial network mapping all major chara...</td>\n",
       "      <td>Sights of Vienna, Austria, flash across the sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>[u' Mystery', u' Thriller']</td>\n",
       "      <td>Advertising executive Roger O. Thornhill is mi...</td>\n",
       "      <td>At the end of an ordinary work day, advertisin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>Yankee Doodle Dandy</td>\n",
       "      <td>[u' Biography', u' Drama', u' Musical']</td>\n",
       "      <td>\\n  In the early days of World War II, Cohan ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank                     title  \\\n",
       "0      0             The Godfather   \n",
       "1      1  The Shawshank Redemption   \n",
       "2      2          Schindler's List   \n",
       "3      3               Raging Bull   \n",
       "4      4                Casablanca   \n",
       "..   ...                       ...   \n",
       "95    95     Rebel Without a Cause   \n",
       "96    96               Rear Window   \n",
       "97    97             The Third Man   \n",
       "98    98        North by Northwest   \n",
       "99    99       Yankee Doodle Dandy   \n",
       "\n",
       "                                         genre  \\\n",
       "0                       [u' Crime', u' Drama']   \n",
       "1                       [u' Crime', u' Drama']   \n",
       "2      [u' Biography', u' Drama', u' History']   \n",
       "3        [u' Biography', u' Drama', u' Sport']   \n",
       "4            [u' Drama', u' Romance', u' War']   \n",
       "..                                         ...   \n",
       "95                                 [u' Drama']   \n",
       "96                 [u' Mystery', u' Thriller']   \n",
       "97  [u' Film-Noir', u' Mystery', u' Thriller']   \n",
       "98                 [u' Mystery', u' Thriller']   \n",
       "99     [u' Biography', u' Drama', u' Musical']   \n",
       "\n",
       "                                            wiki_plot  \\\n",
       "0   On the day of his only daughter's wedding, Vit...   \n",
       "1   In 1947, banker Andy Dufresne is convicted of ...   \n",
       "2   In 1939, the Germans move Polish Jews into the...   \n",
       "3   In a brief scene in 1964, an aging, overweight...   \n",
       "4   It is early December 1941. American expatriate...   \n",
       "..                                                ...   \n",
       "95  \\n\\n\\n\\nJim Stark is in police custody.\\n\\n  \\...   \n",
       "96  \\n\\n\\n\\nJames Stewart as L.B. Jefferies\\n\\n  \\...   \n",
       "97  \\n\\n\\n\\nSocial network mapping all major chara...   \n",
       "98  Advertising executive Roger O. Thornhill is mi...   \n",
       "99   \\n  In the early days of World War II, Cohan ...   \n",
       "\n",
       "                                            imdb_plot  \n",
       "0   In late summer 1945, guests are gathered for t...  \n",
       "1   In 1947, Andy Dufresne (Tim Robbins), a banker...  \n",
       "2   The relocation of Polish Jews from surrounding...  \n",
       "3   The film opens in 1964, where an older and fat...  \n",
       "4   In the early years of World War II, December 1...  \n",
       "..                                                ...  \n",
       "95  Shortly after moving to Los Angeles with his p...  \n",
       "96  L.B. \"Jeff\" Jeffries (James Stewart) recuperat...  \n",
       "97  Sights of Vienna, Austria, flash across the sc...  \n",
       "98  At the end of an ordinary work day, advertisin...  \n",
       "99                                                NaN  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import ipytest\n",
    "ipytest.autoconfig()\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(5)\n",
    "\n",
    "# Read in IMDb and Wikipedia movie data (both in same file)\n",
    "movies_df = pd.read_csv(\"datasets/movies.csv\")\n",
    "\n",
    "print(\"Number of movies loaded: %s \" % (len(movies_df)))\n",
    "\n",
    "# Save a copy for testing purposes\n",
    "test_df = movies_df.copy()\n",
    "\n",
    "# Test got full length of movies data set\n",
    "def test_movies():\n",
    "    assert len(test_df) == 100\n",
    "\n",
    "# Test got all columns of movies data set\n",
    "def test_shape():\n",
    "    assert test_df.shape == (100, 5)\n",
    "# Display the data\n",
    "movies_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to be able to get somewhat of a combined plot between the two plots (imdb and wikipedia) which will give us a more objective plot description, parsing out the tonal words that are present in both and leaving behind only the most pertinent information.\n",
    "\n",
    "First, that means we have to create an overall combined item. We can do this by creating a new column that contains both descriptions in their raw state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
      "platform linux -- Python 3.9.4, pytest-7.4.4, pluggy-1.3.0 -- /home/bobarn/.pyenv/versions/3.9.4/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/bobarn/appacademy/DS_Projects/Related_Movies\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 6 items\n",
      "\n",
      "t_8fc67387e5d347c08ac1149059b8a24f.py::test_movies \u001b[32mPASSED\u001b[0m\u001b[32m                                    [ 16%]\u001b[0m\n",
      "t_8fc67387e5d347c08ac1149059b8a24f.py::test_shape \u001b[32mPASSED\u001b[0m\u001b[32m                                     [ 33%]\u001b[0m\n",
      "t_8fc67387e5d347c08ac1149059b8a24f.py::test_shape2 \u001b[32mPASSED\u001b[0m\u001b[32m                                    [ 50%]\u001b[0m\n",
      "t_8fc67387e5d347c08ac1149059b8a24f.py::test_has_plot \u001b[32mPASSED\u001b[0m\u001b[32m                                  [ 66%]\u001b[0m\n",
      "t_8fc67387e5d347c08ac1149059b8a24f.py::test_stemming \u001b[32mPASSED\u001b[0m\u001b[32m                                  [ 83%]\u001b[0m\n",
      "t_8fc67387e5d347c08ac1149059b8a24f.py::test_tfidf \u001b[32mPASSED\u001b[0m\u001b[32m                                     [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================================== \u001b[32m\u001b[1m6 passed\u001b[0m\u001b[32m in 0.10s\u001b[0m\u001b[32m =========================================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine wiki_plot and imdb_plot into a single column\n",
    "movies_df[\"plot\"] = movies_df[\"wiki_plot\"].astype(str) + \"\\n\" + movies_df[\"imdb_plot\"].astype(str)\n",
    "\n",
    "# Inspect the new DataFrame\n",
    "movies_df.head()\n",
    "\n",
    "# Check that the shape has changed\n",
    "def test_shape2():\n",
    "    assert movies_df.shape == (100, 6)\n",
    "# Check that the new column is named properly\n",
    "def test_has_plot():\n",
    "    assert \"plot\" in movies_df.columns\n",
    "\n",
    "ipytest.run('-vv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, now that we have the combined description we can start to use the nltk package to tokenize the descriptions, separating them into the individual words and phrases like we wanted. The `nltk.tokenize` along with the regex package will allow us to parse out the words and parts separated by spaces and punctuation.\n",
    "\n",
    "Additionally, we can import the `nltk.stem.snowball` package so that we can create a stemming object. The stemming object should be set to English in our case because we are using an English dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', \"'s\", 'and', 'newspap', 'tycoon', 'charl', 'foster', 'kane', 'orson', 'well', 'who', 'also', 'direct', 'and', 'co-wrot', 'the', 'script', 'is', 'dead']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
      "platform linux -- Python 3.9.4, pytest-7.4.4, pluggy-1.3.0 -- /home/bobarn/.pyenv/versions/3.9.4/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/bobarn/appacademy/DS_Projects/Related_Movies\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 6 items\n",
      "\n",
      "t_8fc67387e5d347c08ac1149059b8a24f.py::test_movies \u001b[32mPASSED\u001b[0m\u001b[32m                                    [ 16%]\u001b[0m\n",
      "t_8fc67387e5d347c08ac1149059b8a24f.py::test_shape \u001b[32mPASSED\u001b[0m\u001b[32m                                     [ 33%]\u001b[0m\n",
      "t_8fc67387e5d347c08ac1149059b8a24f.py::test_shape2 \u001b[32mPASSED\u001b[0m\u001b[32m                                    [ 50%]\u001b[0m\n",
      "t_8fc67387e5d347c08ac1149059b8a24f.py::test_has_plot \u001b[32mPASSED\u001b[0m\u001b[32m                                  [ 66%]\u001b[0m\n",
      "t_8fc67387e5d347c08ac1149059b8a24f.py::test_stemming \u001b[32mPASSED\u001b[0m\u001b[32m                                  [ 83%]\u001b[0m\n",
      "t_8fc67387e5d347c08ac1149059b8a24f.py::test_tfidf \u001b[32mPASSED\u001b[0m\u001b[32m                                     [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================================== \u001b[32m\u001b[1m6 passed\u001b[0m\u001b[32m in 0.09s\u001b[0m\u001b[32m =========================================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# Define a function to perform both stemming and tokenization\n",
    "def tokenize_and_stem(text):\n",
    "\n",
    "    # Tokenize by sentence, then by word\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "\n",
    "    # Filter out raw tokens to remove noise\n",
    "    filtered_tokens = [token for token in tokens if re.search('[a-zA-Z]', token)]\n",
    "\n",
    "    # Stem the filtered_tokens\n",
    "    stems = [stemmer.stem(word) for word in filtered_tokens]\n",
    "\n",
    "    return stems\n",
    "\n",
    "# Removes all of what it determines as the excess or noise from the text, keeps only the very root of the words and returns them in a list\n",
    "words_stemmed = tokenize_and_stem(\"It's 1941, and newspaper tycoon Charles Foster Kane (Orson Welles, who also directed and co-wrote the script) is dead\")\n",
    "\n",
    "print(words_stemmed)\n",
    "\n",
    "def test_stemming():\n",
    "    assert words_stemmed == ['it', \"'s\", 'and', 'newspap', 'tycoon', 'charl', 'foster', 'kane', 'orson', 'well', 'who', 'also', 'direct', 'and', 'co-wrot', 'the', 'script', 'is', 'dead']\n",
    "\n",
    "ipytest.run('-vv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will want to add weight to certain words based on frequency and uniqueness across documents. To do this we can use the Term Frequency - Inverse Document Frequency Vectorizer. What that means is that it will check the frequency of a term, increasing the weight but then reduce the weight of the term if it is found in several documents. This will allow us to find the most key terms like character names and thematic language as well as overlook the fluff words like \"the\" and \"and\" and other general structural words in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Instantiate TfidfVectorizer object with stopwords and tokenizer\n",
    "# parameters for efficient processing of text\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 min_df=0.2, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize_and_stem,\n",
    "                                 ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Once we establish a TF-IDF Vectorizer, we must modify the text to fit into the corresponding numeric form of the data which the computer will be able to understand and derive meaning from. To do this, we can call the <code>fit_transform()</code> method of the <code>TfidfVectorizer</code> object. </p>\n",
    "<p>In doing this process, we also set the <code>stop_words</code> parameter to 'english' so that the words that are dropped in the evaluation of the weight of the words are the words included in a set list of words in the nltk module.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bobarn/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/bobarn/.pyenv/versions/3.9.4/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tfidf_matrix = tfidf_vectorizer.fit_transform([x for x in movies_df[\"plot\"]])\n",
    "\n",
    "print(tfidf_matrix.shape)\n",
    "\n",
    "def test_tfidf():\n",
    "    assert tfidf_matrix.shape[0] == (100)\n",
    "\n",
    "ipytest.run('-vv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
